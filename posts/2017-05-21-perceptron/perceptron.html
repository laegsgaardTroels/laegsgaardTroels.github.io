<!doctype html>
<html lang="en">
  <head>

      <style>
        img {
          max-width: 100%;
          margin: auto;
          display: block;
        }
        figcaption {
          max-width: 100%;
          margin: auto;
          display: block;
        }
        code {
          font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
          background-color: #f5f5f5;
          padding: .2em .4em;
          font-size: 85%;
          margin: 0;
        }
        pre {
          margin: 1em 0;
          background-color: #f5f5f5;
          padding: 1em;
          overflow: auto;
        }
        pre code {
          padding: 0;
          overflow: visible;
          overflow-wrap: normal;
        }
        .sourceCode {
         background-color: #f5f5f5;
         overflow: visible;
        }
        hr {
          background-color: #1a1a1a;
          border: none;
          height: 1px;
          margin: 1em 0;
        }
        table {
          margin: 1em 0;
          border-collapse: collapse;
          width: 100%;
          overflow-x: auto;
          display: block;
          font-variant-numeric: lining-nums tabular-nums;
        }
        table caption {
          margin-bottom: 0.75em;
        }
        tbody {
          margin-top: 0.5em;
          border-top: 1px solid #1a1a1a;
          border-bottom: 1px solid #1a1a1a;
        }
        th {
          border-top: 1px solid #1a1a1a;
          padding: 0.25em 0.5em 0.25em 0.5em;
        }
        td {
          padding: 0.125em 0.5em 0.25em 0.5em;
        }
        header {
          margin-bottom: 4em;
          text-align: center;
        }
        #TOC li {
          list-style: none;
        }
        #TOC ul {
          padding-left: 1.3em;
        }
        #TOC > ul {
          padding-left: 0;
        }
        #TOC a:not(:hover) {
          text-decoration: none;
        }
        code{white-space: pre-wrap;}
        span.smallcaps{font-variant: small-caps;}
        span.underline{text-decoration: underline;}
        div.column{display: inline-block; vertical-align: top; width: 50%;}
        div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
        ul.task-list{list-style: none;}
      </style>
              <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
      
                <!-- Using Bootstrap starter template: https://getbootstrap.com/docs/4.0/getting-started/introduction/-->
                <!-- Required meta tags -->
                <meta charset="utf-8">
                <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
                <link rel="shortcut icon" type="image/png" href="/assets/images/2017-09-29-adaboost-the-original-boosting-algorithm/AdaBoostExampleData.png">

                <!-- <link rel="stylesheet" href="/assets/css/bootstrap.min.css">Bootstrap CSS -->


                <!-- 
                <script type="text/x-mathjax-config">
                    MathJax.Hub.Config({
                    jax: ["input/TeX", "output/HTML-CSS"],
                    tex2jax: {
                      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
                      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
                      processEscapes: true,
                      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                    }
                    //,
                    //displayAlign: "left",
                    //displayIndent: "2em"
                  });
                </script>
                <script type="text/javascript" async
                        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
                </script>
                MathJax -->

                <!-- Font Awesome CSS -->
                <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

                <!-- Disqus -->
                <script id="dsq-count-scr" src="//machinelearningnotes-1.disqus.com/count.js" async></script>
                      <script
                      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
                      type="text/javascript"></script>
      
    <title>Perceptron</title>
  </head>
  <body>

        <nav class="navbar navbar-expand-lg navbar-light bg-light">
            <a class="navbar-brand" href="/">ML-Notes</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
                <div class="navbar-nav">
                    <a class="nav-link" href="/index.html"> Blog </a>
                    <a class="nav-link" href="/courses.html"> Courses </a>
                    <a class="nav-link" href="/about.html"> About </a>
                </div>
            </div>
        </nav>

    
    <div class="container">
        <br>
        <div class="page-header">
            <div class="pull-left">
                <h1>Perceptron</h1>
                <strong>Algorithm</strong>
                <div class="text-muted">2017-05-21</div>
            </div>
            
            <div class="pull-right">

                                <div class="text-right">
                    <a href="https://github.com/laegsgaardTroels/perceptron">
                        [<i>View source</i> <span class="fa fa-github"></span>]
                    </a>
                </div>
                
            </div>
            <div class="clearfix"></div>
        </div>
        

        <br>
        <p>The Perceptron by Rosenblat is one of the earliest machine
        learning algorithms. It was proposed as a model of an artificial
        neuron, and can be used for classification.<!--more--> The
        Perceptron belongs to the class of models specified by,</p>
        <p><span class="math display">\[
        \begin{aligned}
            h(x) &amp; = f(\sum_{j=1}^{m}w_jx_j + b), \quad
        w\in\mathbb{R}^d, b\in\mathbb{R}
        \end{aligned}
        \]</span></p>
        <p>where <span class="math inline">\(f\)</span> is a non-linear
        function, for the Perceptron <span
        class="math inline">\(f=\text{sign}\)</span>. This class of
        models is the basic building block for <strong>feedforward
        neural networks</strong>.</p>
        <p>The perceptron works like an artificial neuron, when fed an
        <span class="math inline">\(x\in\mathbb{R}^d\)</span> to be
        classified, the observations will be weighed using the weights:
        <span
        class="math inline">\(w_1,w_2,\dots,w_m\in\mathbb{R}\)</span>;
        if the artificial neuron is stimulated enough, <span
        class="math inline">\(\sum_jw_jx_j&gt;-b \Rightarrow
        h(x)=1\)</span>, then the neuron fires.</p>
        <p><img src="/assets/images/2017-05-21-perceptron/perceptron.svg" width="800" height="auto"></p>
        <p>A problem with the perceptron is that the activation function
        is not differentiable, making it unclear how to fit a multilayer
        perceptron, defined below, with this choice of activation
        function, instead one can choose a differentiable
        activation-function like the sigmoid function: <span
        class="math inline">\(f(x)=\sigma(x)=\frac{1}{1+e^{-x}}\)</span>,
        used in logistic regression, which has the nice property that:
        <span
        class="math inline">\(\sigma&#39;(x)=\sigma(x)(1-\sigma(x))\)</span>,
        making it easy to differentiate.</p>
        <p>The Perceptron can be fit to data using the
        <strong>perceptron learning algorithm</strong> which can be
        derived from the <strong>stochastic gradient descent</strong>
        (SGD) algorithm for optimization. SGD is a <strong>gradient
        based optimization method</strong>. Gradient based optimization
        methods are the main workhose in todays practice for fitting
        neural networks.</p>
        <p>To derive it use the loss function:</p>
        <p><span class="math display">\[
        \begin{aligned}
        \mathcal{L}(w)
        &amp;= - \sum_{i:h(x_i)\neq y_i}w&#39;x_i y_i\\
        &amp;= - \sum_{i=1}^{N} \min(w&#39;x_i y_i,0)\\
        &amp;= - \sum_{i=1}^{N} L_i(w)
        \end{aligned}
        \]</span></p>
        <p>One notices that for a single observation <span
        class="math inline">\((x_i, y_i)\)</span> that:</p>
        <p><span class="math display">\[
        \begin{cases}
            \text{Correctly classified: }w&#39;x_iy_i&gt;0 \Rightarrow
        L_i(w)=\min(w&#39;x_i y_i,0)=0 \Rightarrow
        \frac{\partial}{\partial w} L_i(w) = 0\\
            \text{Wrongly classified: } \  w&#39;x_iy_i&lt;0 \Rightarrow
        L_i(w)=\min(w&#39;x_i y_i,0)&lt;0 \Rightarrow
        \frac{\partial}{\partial w} L_i(w) = x_i y_i
        \end{cases}
        \]</span></p>
        <p>So applying stochastic gradient descent with <span
        class="math inline">\(\eta\in(0,1)\)</span> amounts to the
        update rule:</p>
        <p><span class="math display">\[
        \begin{aligned}
        w_{t+1}
        &amp;= w_t - \eta \frac{\partial}{\partial w} L_i(w) \\
        &amp;= \begin{cases}
            \text{Correctly classified: } w_t \\
            \text{Wrongly classified: } w_t - \eta x_i y_i
        \end{cases}
        \end{aligned}
        \]</span></p>
        <p>With a new observation <span class="math inline">\((x_i,
        y_i)\)</span> in each iteration. That is basically the
        perceptron learning algorithm.</p>
        <h1 id="references">References</h1>
        <p>[1] Rosenblatt. “The Perceptron: A probalistic model for
        information storage and organization in the brain”. 1958.</p>
        <br>
        <br>

        <!--- Disqus --->
        <div id="disqus_thread"></div>
        <script>
            /**
            *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
                 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
            /*
           var disqus_config = function () {
           this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
           this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
           };
                 */
            (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://machinelearningnotes-1.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>        
    </div>


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>    
  </body>
</html>
